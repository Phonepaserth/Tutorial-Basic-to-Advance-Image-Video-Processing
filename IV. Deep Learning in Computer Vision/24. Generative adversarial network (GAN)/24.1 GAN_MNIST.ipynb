{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"coursera":{"schema_names":["GANSC1-1A"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","source":["![Memories Teach](https://lh3.google.com/u/2/d/11o4JyBYhHcmz-LSt63GpOs4lfW9j39T_=w1912-h954-iv1)\n","\n","\n","`Basic to Advance in Google colab's for image processing, pattern recognition and computer vision`\n","\n","[Phonepaserth SISAYKEO]\n","\n","Reference: visioncolab"],"metadata":{"id":"EJYLOWaNe7_6"}},{"cell_type":"markdown","metadata":{"id":"1czVdIlqnImH"},"source":["# Simple GAN (for MNIST)\n","\n","From first assignment of Coursera Course (Course 1 / Week 1)\n","\n","Domingo Mery"]},{"cell_type":"markdown","metadata":{"id":"wU8DDM6l9rZb"},"source":["## Initialization\n"]},{"cell_type":"code","metadata":{"id":"JfkorNJrnmNO"},"source":["import torch\n","from torch import nn\n","from tqdm.auto import tqdm\n","from torchvision import transforms\n","from torchvision.datasets import MNIST # Training dataset\n","from torchvision.utils import make_grid\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","torch.manual_seed(0) # Set for testing purposes, please do not change!\n","\n","def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n","    '''\n","    Function for visualizing images: Given a tensor of images, number of images, and\n","    size per image, plots and prints the images in a uniform grid.\n","    '''\n","    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n","    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n","    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yCpKwWkukahN"},"source":["## MNIST dataset"]},{"cell_type":"code","metadata":{"id":"ohhXQUMXkYFY"},"source":["!wget https://www.dropbox.com/s/3vm9pavwc59i4cu/MNIST.zip\n","!unzip MNIST.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1A1M6kpnfxw"},"source":["## Generator\n"]},{"cell_type":"code","metadata":{"id":"bZbqdw21hK5i"},"source":["def get_noise(n_samples, z_dim, device='cpu'):\n","    '''\n","    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n","    creates a tensor of that shape filled with random numbers from the normal distribution.\n","    Parameters:\n","        n_samples: the number of samples to generate, a scalar\n","        z_dim: the dimension of the noise vector, a scalar\n","        device: the device type\n","    '''\n","    noise = torch.randn(n_samples,z_dim).to(device)\n","    return noise\n","\n","def get_generator_block(input_dim, output_dim):\n","    '''\n","    Function for returning a block of the generator's neural network\n","    given input and output dimensions.\n","    Parameters:\n","        input_dim: the dimension of the input vector, a scalar\n","        output_dim: the dimension of the output vector, a scalar\n","    Returns:\n","        a generator neural network layer, with a linear transformation\n","          followed by a batch normalization and then a relu activation\n","    '''\n","    return nn.Sequential(\n","        nn.Linear(input_dim, output_dim),\n","        nn.BatchNorm1d(output_dim),\n","        nn.ReLU(inplace=True),\n","    )\n","\n","\n","class Generator(nn.Module):\n","    '''\n","    Generator Class\n","    Values:\n","        z_dim: the dimension of the noise vector, a scalar\n","        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n","          (MNIST images are 28 x 28 = 784 so that is your default)\n","        hidden_dim: the inner dimension, a scalar\n","    '''\n","    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n","        super(Generator, self).__init__()\n","        self.gen = nn.Sequential(\n","            get_generator_block(z_dim, hidden_dim),\n","            get_generator_block(hidden_dim, hidden_dim * 2),\n","            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n","            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n","            nn.Linear(hidden_dim * 8, im_dim),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, noise):\n","        '''\n","        Function for completing a forward pass of the generator: Given a noise tensor,\n","        returns generated images.\n","        Parameters:\n","            noise: a noise tensor with dimensions (n_samples, z_dim)\n","        '''\n","        return self.gen(noise)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9fScH98nkYH"},"source":["## Discriminator"]},{"cell_type":"code","metadata":{"id":"sYi8YFcseYFK"},"source":["def get_discriminator_block(input_dim, output_dim):\n","    '''\n","    Discriminator Block\n","    Function for returning a neural network of the discriminator given input and output dimensions.\n","    Parameters:\n","        input_dim: the dimension of the input vector, a scalar\n","        output_dim: the dimension of the output vector, a scalar\n","    Returns:\n","        a discriminator neural network layer, with a linear transformation\n","          followed by an nn.LeakyReLU activation with negative slope of 0.2\n","          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n","    '''\n","    return nn.Sequential(\n","        nn.Linear(input_dim, output_dim),\n","        nn.LeakyReLU(0.2)\n","    )\n","\n","class Discriminator(nn.Module):\n","    '''\n","    Discriminator Class\n","    Values:\n","        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n","            (MNIST images are 28x28 = 784 so that is your default)\n","        hidden_dim: the inner dimension, a scalar\n","    '''\n","    def __init__(self, im_dim=784, hidden_dim=128):\n","        super(Discriminator, self).__init__()\n","        self.disc = nn.Sequential(\n","            get_discriminator_block(im_dim, hidden_dim * 4),\n","            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n","            get_discriminator_block(hidden_dim * 2, hidden_dim),\n","            nn.Linear(hidden_dim,1)\n","        )\n","\n","    def forward(self, image):\n","        '''\n","        Function for completing a forward pass of the discriminator: Given an image tensor,\n","        returns a 1-dimension tensor representing fake/real.\n","        Parameters:\n","            image: a flattened image tensor with dimension (im_dim)\n","        '''\n","        return self.disc(image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLoJY7xAirWJ"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"IFLQ039u-qdu"},"source":["# Set your parameters\n","criterion = nn.BCEWithLogitsLoss()\n","n_epochs = 200\n","z_dim = 64\n","display_step = 500\n","batch_size = 128\n","lr = 0.00001\n","#device = 'cuda'\n","device = 'cpu'\n","# Load MNIST dataset as tensors\n","dataloader = DataLoader(\n","    MNIST('.', download=False, transform=transforms.ToTensor()),\n","    batch_size=batch_size,\n","    shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sDFRZ8tg_Y57"},"source":["gen = Generator(z_dim).to(device)\n","gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n","disc = Discriminator().to(device)\n","disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYzBtiYyz8IJ"},"source":["def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n","    '''\n","    Return the loss of the discriminator given inputs.\n","    Parameters:\n","        gen: the generator model, which returns an image given z-dimensional noise\n","        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n","        criterion: the loss function, which should be used to compare\n","               the discriminator's predictions to the ground truth reality of the images\n","               (e.g. fake = 0, real = 1)\n","        real: a batch of real images\n","        num_images: the number of images the generator should produce,\n","                which is also the length of the real images\n","        z_dim: the dimension of the noise vector, a scalar\n","        device: the device type\n","    Returns:\n","        disc_loss: a torch scalar loss value for the current batch\n","    '''\n","\n","    noise       = get_noise(num_images, z_dim, device)\n","    fake_images = gen(noise)\n","\n","    fake_pred   = disc(fake_images.detach())\n","    fake_true   = torch.zeros_like(fake_pred)\n","    fake_loss   = criterion(fake_pred,fake_true)\n","\n","    real_pred   = disc(real)\n","    real_true   = torch.ones_like(real_pred)\n","    real_loss   = criterion(real_pred,real_true)\n","\n","    disc_loss   = (fake_loss+real_loss)/2\n","\n","    #### END CODE HERE ####\n","    return disc_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zV_8i6y30nTE"},"source":["def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n","\n","    '''\n","    Return the loss of the generator given inputs.\n","    Parameters:\n","        gen: the generator model, which returns an image given z-dimensional noise\n","        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n","        criterion: the loss function, which should be used to compare\n","               the discriminator's predictions to the ground truth reality of the images\n","               (e.g. fake = 0, real = 1)\n","        num_images: the number of images the generator should produce,\n","                which is also the length of the real images\n","        z_dim: the dimension of the noise vector, a scalar\n","        device: the device type\n","    Returns:\n","        gen_loss: a torch scalar loss value for the current batch\n","    '''\n","\n","    noise       = get_noise(num_images, z_dim, device)\n","    fake_images = gen(noise)\n","\n","    fake_pred   = disc(fake_images)\n","\n","    fake_true   = torch.ones_like(fake_pred)\n","    gen_loss    = criterion(fake_pred,fake_true)\n","\n","    return gen_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXptQZcwrBrq"},"source":["cur_step = 0\n","mean_generator_loss = 0\n","mean_discriminator_loss = 0\n","test_generator = True # Whether the generator should be tested\n","gen_loss = False\n","error = False\n","for epoch in range(n_epochs):\n","\n","    # Dataloader returns the batches\n","    for real, _ in tqdm(dataloader):\n","        cur_batch_size = len(real)\n","\n","        # Flatten the batch of real images from the dataset\n","        real = real.view(cur_batch_size, -1).to(device)\n","\n","        ### Update discriminator ###\n","        # Zero out the gradients before backpropagation\n","        disc_opt.zero_grad()\n","\n","        # Calculate discriminator loss\n","        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n","\n","        # Update gradients\n","        disc_loss.backward(retain_graph=True)\n","\n","        # Update optimizer\n","        disc_opt.step()\n","\n","        # For testing purposes, to keep track of the generator weights\n","        if test_generator:\n","            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n","\n","        ### Update generator ###\n","\n","        gen_opt.zero_grad()\n","\n","        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n","\n","        gen_loss.backward(retain_graph=True)\n","\n","        gen_opt.step()\n","\n","        # Keep track of the average discriminator loss\n","        mean_discriminator_loss += disc_loss.item() / display_step\n","\n","        # Keep track of the average generator loss\n","        mean_generator_loss += gen_loss.item() / display_step\n","\n","        ### Visualization code ###\n","        if cur_step % display_step == 0 and cur_step > 0:\n","            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n","            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n","            fake = gen(fake_noise)\n","            show_tensor_images(fake)\n","            show_tensor_images(real)\n","            mean_generator_loss = 0\n","            mean_discriminator_loss = 0\n","        cur_step += 1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRciy40qSDQz"},"source":[],"execution_count":null,"outputs":[]}]}