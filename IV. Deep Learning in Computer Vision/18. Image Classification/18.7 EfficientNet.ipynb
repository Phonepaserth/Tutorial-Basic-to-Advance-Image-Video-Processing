{"cells":[{"cell_type":"markdown","source":["![Memories Teach](https://lh3.google.com/u/2/d/11o4JyBYhHcmz-LSt63GpOs4lfW9j39T_=w1912-h954-iv1)\n","\n","\n","`Basic to Advance in Google colab's for image processing, pattern recognition and computer vision`\n","\n","[Phonepaserth SISAYKEO]\n","\n","Reference: visioncolab"],"metadata":{"id":"TGqbZ6g4h924"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYgMJJi4X2Y0","outputId":"d2a66df6-2ee0-4f9a-f5ce-cd762f73371a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting efficientnet_pytorch\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet_pytorch\n","  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=17deeb47f495617a4936abc088a3f5a58f0dafe8e2b540af7f62e461a3d5a559\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","Successfully built efficientnet_pytorch\n","Installing collected packages: efficientnet_pytorch\n","Successfully installed efficientnet_pytorch-0.7.1\n"]}],"source":["!pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yhc3LdzuYghn"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","import copy\n","import random\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.figsize'] = [15, 7]\n","\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","from efficientnet_pytorch import EfficientNet\n","import gc"]},{"cell_type":"markdown","metadata":{"id":"K-EYpBPIrVck"},"source":["# Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTs2A7E8rW14"},"outputs":[],"source":["def accuracy(predictions, labels):\n","    #round predictions to the closest integer\n","    probs = torch.softmax(predictions, dim=1)\n","    winners = probs.argmax(dim=1)\n","    corrects = (winners == labels).float()\n","    acc = corrects.sum() / len(corrects)\n","    return acc\n","\n","def train_epoch(model, iterator, optimizer, criterion, device):\n","    epoch_loss = 0\n","    epoch_acc  = 0\n","    model.train()\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        img, label = batch\n","        img = img.to(device)\n","        label = label.to(device)\n","\n","        predictions = model(img)#.squeeze()\n","\n","        loss = criterion(predictions, label)\n","        acc  = accuracy(predictions, label)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc  += acc.item()\n","\n","    return epoch_loss/len(iterator), epoch_acc/len(iterator)\n","\n","def eval_epoch(model, iterator, criterion, device):\n","\n","    #initialize every epoch\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    #deactivating dropout layers\n","    model.eval()\n","\n","    #deactivates autograd\n","    with torch.no_grad():\n","        for batch in iterator:\n","\n","            img, label = batch\n","            img = img.to(device)\n","            label = label.to(device)\n","\n","            #convert to 1d tensor\n","            predictions = model(img)\n","\n","            #compute loss and accuracy\n","            loss = criterion(predictions, label)\n","            acc = accuracy(predictions, label)\n","\n","            #keep track of loss and accuracy\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","def testing(model, iterator, batch_size, device):\n","\n","    preds = []\n","    lbls  = []\n","    predictions = torch.Tensor(len(iterator)*batch_size).to(device)\n","    labels      = torch.Tensor(len(iterator)*batch_size).to(device)\n","\n","\n","    #deactivating dropout layers\n","    model.eval()\n","\n","    #deactivates autograd\n","    with torch.no_grad():\n","        for batch in iterator:\n","\n","            img, label = batch\n","            img = img.to(device)\n","            label = label.to(device)\n","\n","            #convert to 1d tensor\n","            scores = model(img)\n","            probs = torch.softmax(scores, dim=1)\n","            winners = probs.argmax(dim=1)\n","            preds.append(winners)\n","            lbls.append(label)\n","\n","    torch.cat(preds, out=predictions)\n","    torch.cat(lbls, out=labels)\n","\n","    return predictions.cpu().numpy(), labels.cpu().numpy()\n","\n","def metrics(predictions, labels):\n","    cm = confusion_matrix(labels, predictions)\n","    Accuracy = np.sum(np.diag(cm))/np.sum(cm)\n","    Pr = np.mean(np.diag(cm) / np.sum(cm, axis = 0))\n","    Re = np.mean(np.diag(cm) / np.sum(cm, axis = 1))\n","    F1 = 2*(Pr*Re)/(Pr + Re)\n","    return Accuracy, Pr, Re, F1, cm\n","\n","def num_trainable_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ki58hIk9sCsJ"},"outputs":[],"source":["def train(model, train_dataloader, val_dataloader, optimizer, criterion, device, num_epochs,\n","          saved_models_folder, saved_scores_folder, save_path, printfreq=1):\n","\n","    train_loss_hist = []\n","    train_acc_hist  = []\n","    val_loss_hist   = []\n","    val_acc_hist    = []\n","\n","    best_val_loss = float('inf')\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    t0 = time.time()\n","    print(' Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]')\n","    print('-'*79)\n","\n","    for epoch in range(num_epochs):\n","        t1 = time.time()\n","        st = '        '\n","\n","        # Training metrics\n","        train_loss, train_acc = train_epoch(model, train_dataloader, optimizer, criterion, device)\n","        train_loss_hist.append(train_loss)\n","        train_acc_hist.append(train_acc)\n","\n","        # Validation metrics\n","        val_loss, val_acc     = eval_epoch(model, val_dataloader, criterion, device)\n","        val_loss_hist.append(val_loss)\n","        val_acc_hist.append(val_acc)\n","\n","        # Update best model\n","        if val_loss < best_val_loss:\n","            st = '     ***'\n","            best_val_loss = val_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            torch.save(best_model_wts, os.path.join(saved_models_folder, 'best_' + save_path))\n","\n","        if (epoch + 1) % printfreq == 0:\n","            t2 = (time.time() - t1)/60\n","            s = f'{epoch+1:6}{train_loss:12.4f}{val_loss:13.4f}{train_acc:13.4f}{val_acc:12.4f}{st}{t2:10.1f}'\n","            print(s)\n","\n","        # Save current model and training information\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': val_loss,\n","        }, os.path.join(saved_models_folder, save_path))\n","\n","        # Save the loss and accuracy values\n","        np.save(os.path.join(saved_scores_folder, f'{save_path}_train_loss'), train_loss_hist)\n","        np.save(os.path.join(saved_scores_folder, f'{save_path}_train_acc'), train_acc_hist)\n","        np.save(os.path.join(saved_scores_folder, f'{save_path}_val_loss'), val_loss_hist)\n","        np.save(os.path.join(saved_scores_folder, f'{save_path}_val_acc'), val_acc_hist)\n","\n","    tfinal = (time.time() - t0)/60\n","    print('-'*79)\n","    print(f'Total time [min] for {num_epochs} Epochs: {tfinal:.1f}')\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTogd1I6rL07"},"outputs":[],"source":["def display_train_metrics(saved_scores_folder, save_path):\n","\n","    # Loss\n","    train_loss_hist = np.load(os.path.join(saved_scores_folder, f'{save_path}_train_loss.npy'))\n","    val_loss_hist = np.load(os.path.join(saved_scores_folder, f'{save_path}_val_loss.npy'))\n","\n","    # Acc\n","    train_acc_hist = np.load(os.path.join(saved_scores_folder, f'{save_path}_train_acc.npy'))\n","    val_acc_hist = np.load(os.path.join(saved_scores_folder, f'{save_path}_val_acc.npy'))\n","\n","    num_epochs = len(train_loss_hist)\n","    epochs = range(1, num_epochs + 1)\n","\n","\n","    plt.plot(epochs, train_loss_hist, marker='o', label='Training')\n","    plt.plot(epochs, val_loss_hist, marker='o', label='Validation')\n","    plt.title('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    plt.plot(epochs, train_acc_hist, marker='o', label='Training')\n","    plt.plot(epochs, val_acc_hist, marker='o', label='Validation')\n","    plt.title('Accuracy')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hw9bcE_AtA-x"},"outputs":[],"source":["def reset_model(model):\n","    for layer in model.children():\n","        if hasattr(layer, 'reset_parameters'):\n","            layer.reset_parameters()"]},{"cell_type":"markdown","metadata":{"id":"Sf_ZwMumpVMi"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JxjDZAIsqRt"},"outputs":[],"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","def initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model = None\n","    input_size = 0\n","\n","    if 'resnet' in model_name:\n","        if model_name == 'resnet18':\n","            \"\"\" Resnet18\"\"\"\n","            model = models.resnet18(pretrained=use_pretrained)\n","\n","        if model_name == 'resnet34':\n","            \"\"\" Resnet34\"\"\"\n","            model = models.resnet34(pretrained=use_pretrained)\n","        if model_name == 'resnet50':\n","            \"\"\" Resnet50\"\"\"\n","            model = models.resnet50(pretrained=use_pretrained)\n","        if model_name == 'resnet101':\n","            \"\"\" Resnet101\"\"\"\n","            model = models.resnet101(pretrained=use_pretrained)\n","        if model_name == 'resnet152':\n","            \"\"\" Resnet152\"\"\"\n","            model = models.resnet152(pretrained=use_pretrained)\n","\n","        set_parameter_requires_grad(model, feature_extract)\n","        num_ftrs = model.fc.in_features\n","        model.fc = nn.Linear(num_ftrs, num_classes)\n","        input_size = 224\n","\n","    elif 'effnet' in model_name:\n","        model_n = model_name[-1]\n","        full_model_name = f'efficientnet-b{model_n}'\n","        model = EfficientNet.from_pretrained(full_model_name, num_classes=num_classes)\n","        input_size = EfficientNet.get_image_size(full_model_name)\n","\n","\n","    elif model_name == \"alexnet\":\n","        \"\"\" Alexnet\n","        \"\"\"\n","        model = models.alexnet(pretrained=use_pretrained)\n","        set_parameter_requires_grad(model, feature_extract)\n","        num_ftrs = model.classifier[6].in_features\n","        model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n","        input_size = 224\n","\n","    else:\n","        print(\"Invalid model name, exiting...\")\n","        exit()\n","\n","    return model, input_size"]},{"cell_type":"markdown","metadata":{"id":"i5-p7h5xb0Ze"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4dEbsuQ6tcR","outputId":"9cf13a54-3725-4e6e-d98b-a122b81016cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-07-19 19:49:31--  https://www.dropbox.com/s/nzrvuoos7sgl5dh/exp4val.zip\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/nzrvuoos7sgl5dh/exp4val.zip [following]\n","--2023-07-19 19:49:32--  https://www.dropbox.com/s/raw/nzrvuoos7sgl5dh/exp4val.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com/cd/0/inline/CAKsrlKIjrlljBwhI9LEpjlQovsc-ZfSmp6S9Sfq4SZO96uHmLGsE2rndy3FEn0MlPMBDJpkgEbAZjsktG2Kgy88SfMwuYiJulvYAI6seHVMdAsjBrCb8sJLe5vuHfoSPTx7bauq68j5_5xg4pnWHX6Gk0YsHBZlh6Y3D0AOZCqbAg/file# [following]\n","--2023-07-19 19:49:32--  https://uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com/cd/0/inline/CAKsrlKIjrlljBwhI9LEpjlQovsc-ZfSmp6S9Sfq4SZO96uHmLGsE2rndy3FEn0MlPMBDJpkgEbAZjsktG2Kgy88SfMwuYiJulvYAI6seHVMdAsjBrCb8sJLe5vuHfoSPTx7bauq68j5_5xg4pnWHX6Gk0YsHBZlh6Y3D0AOZCqbAg/file\n","Resolving uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com (uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6031:15::a27d:510f\n","Connecting to uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com (uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/CAKDtBWcjvblEBP8xnyBWgdQfzJgrlUAWKww2QYyuP_2GMPKox_buGkCq2k31ZMMhJc4e8RFnAgailjofJCwKP-1AjahfMwCddZoaMKpIZiSPl6uvQAIPPDu4T_vDiCa50bPRBDM9p1E-Yk7hNXQVYpeMIAp8BtMpByovKSmgA93MqX1Hyhz9Ez7Fl7kUeaN4nh8JGFllZqmghmwwK5cPT8w2EfUvmBQzkdv6nHCLAVGYgBRIc2xINV8pFzWYpowGEAPAvcO-xtLaLQGveRKE3W17FpV9B_Fn7o2xc4ZWF9yKHrqV1pImHdOp0F7NVIHhrVsOhZ3Rxv1mYvpW0LQRDrRv2X9nZt5Ix7oxWlQ0t2DAHSMi_rBxO_BcTPxIVFJyOszjyac1RuXxCQtAQjVcEgZTrfv1KOW4Yb4s-ypvpG89g/file [following]\n","--2023-07-19 19:49:33--  https://uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com/cd/0/inline2/CAKDtBWcjvblEBP8xnyBWgdQfzJgrlUAWKww2QYyuP_2GMPKox_buGkCq2k31ZMMhJc4e8RFnAgailjofJCwKP-1AjahfMwCddZoaMKpIZiSPl6uvQAIPPDu4T_vDiCa50bPRBDM9p1E-Yk7hNXQVYpeMIAp8BtMpByovKSmgA93MqX1Hyhz9Ez7Fl7kUeaN4nh8JGFllZqmghmwwK5cPT8w2EfUvmBQzkdv6nHCLAVGYgBRIc2xINV8pFzWYpowGEAPAvcO-xtLaLQGveRKE3W17FpV9B_Fn7o2xc4ZWF9yKHrqV1pImHdOp0F7NVIHhrVsOhZ3Rxv1mYvpW0LQRDrRv2X9nZt5Ix7oxWlQ0t2DAHSMi_rBxO_BcTPxIVFJyOszjyac1RuXxCQtAQjVcEgZTrfv1KOW4Yb4s-ypvpG89g/file\n","Reusing existing connection to uc68051f10bf1a6f975227acb35e.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 64265389 (61M) [application/zip]\n","Saving to: ‘exp4val.zip’\n","\n","exp4val.zip         100%[===================>]  61.29M  22.2MB/s    in 2.8s    \n","\n","2023-07-19 19:49:37 (22.2 MB/s) - ‘exp4val.zip’ saved [64265389/64265389]\n","\n"]}],"source":["# skin lesions: 7 classes\n","!wget https://www.dropbox.com/s/nzrvuoos7sgl5dh/exp4val.zip\n","!unzip -qq exp4val.zip\n","fpath = ''\n","num_classes =  7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNc7OfiTiblU"},"outputs":[],"source":["def get_dataloaders(data_dir, input_size, batch_size=32):\n","    data_transforms = {\n","        'train': transforms.Compose([\n","            transforms.RandomResizedCrop(input_size),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ]),\n","        'val': transforms.Compose([\n","            transforms.Resize(input_size),\n","            transforms.CenterCrop(input_size),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ]),\n","        'test': transforms.Compose([\n","            transforms.Resize(input_size),\n","            transforms.CenterCrop(input_size),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","        }\n","    print(\"Initializing Datasets and Dataloaders...\")\n","\n","    # Create training and validation datasets\n","    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n","    # Create training and validation dataloaders\n","    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=2) for x in ['train', 'val', 'test']}\n","    return dataloaders_dict\n"]},{"cell_type":"markdown","metadata":{"id":"VwUbus7dqH50"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ued8M7Q0jjQy"},"outputs":[],"source":["data_dir = ''\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RE5NKFXXPXUe"},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdS5UxM3PaVm","outputId":"f50af92d-e7af-43ef-e14f-6ff762171dcb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n","100%|██████████| 20.4M/20.4M [00:01<00:00, 18.0MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b0\n","EfficientNet(\n","  (_conv_stem): Conv2dStaticSamePadding(\n","    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n","    (static_padding): ZeroPad2d((0, 1, 0, 1))\n","  )\n","  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_blocks): ModuleList(\n","    (0): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        32, 8, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        8, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (1): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n","        (static_padding): ZeroPad2d((0, 1, 0, 1))\n","      )\n","      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        96, 4, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        4, 96, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (2): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (3): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n","        (static_padding): ZeroPad2d((1, 2, 1, 2))\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (4): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (5): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n","        (static_padding): ZeroPad2d((0, 1, 0, 1))\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (6-7): 2 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        480, 20, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        20, 480, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (8): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        480, 20, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        20, 480, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (9-10): 2 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        672, 28, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        28, 672, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (11): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n","        (static_padding): ZeroPad2d((1, 2, 1, 2))\n","      )\n","      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        672, 28, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        28, 672, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (12-14): 3 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (15): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","  )\n","  (_conv_head): Conv2dStaticSamePadding(\n","    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n","    (static_padding): Identity()\n","  )\n","  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","  (_dropout): Dropout(p=0.2, inplace=False)\n","  (_fc): Linear(in_features=1280, out_features=7, bias=True)\n","  (_swish): MemoryEfficientSwish()\n",")\n","  4.0165\n"]}],"source":["model_name = 'effnetb0'\n","model, input_size = initialize_model(model_name, 7)\n","\n","print(model)\n","\n","p = count_parameters(model)\n","\n","print(f'{p/1e6:8.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"kbr0tV6ahEOO"},"source":["## b0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"___pSNnnjs6A","outputId":"bc5a9b91-003f-4c1e-b156-4be1a4aee081"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b0\n","Initializing Datasets and Dataloaders...\n"]}],"source":["model_name = 'effnetb0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiqTi3URO3WT","outputId":"b16d11bf-b46c-4c55-ae19-6fac5fe19e28"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["EfficientNet(\n","  (_conv_stem): Conv2dStaticSamePadding(\n","    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n","    (static_padding): ZeroPad2d((0, 1, 0, 1))\n","  )\n","  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_blocks): ModuleList(\n","    (0): MBConvBlock(\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        32, 8, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        8, 32, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (1): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n","        (static_padding): ZeroPad2d((0, 1, 0, 1))\n","      )\n","      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        96, 4, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        4, 96, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (2): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (3): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n","        (static_padding): ZeroPad2d((1, 2, 1, 2))\n","      )\n","      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        144, 6, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        6, 144, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (4): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (5): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n","        (static_padding): ZeroPad2d((0, 1, 0, 1))\n","      )\n","      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        240, 10, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        10, 240, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (6-7): 2 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        480, 20, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        20, 480, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (8): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        480, 20, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        20, 480, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (9-10): 2 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        672, 28, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        28, 672, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (11): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n","        (static_padding): ZeroPad2d((1, 2, 1, 2))\n","      )\n","      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        672, 28, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        28, 672, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (12-14): 3 x MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n","        (static_padding): ZeroPad2d((2, 2, 2, 2))\n","      )\n","      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","    (15): MBConvBlock(\n","      (_expand_conv): Conv2dStaticSamePadding(\n","        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_depthwise_conv): Conv2dStaticSamePadding(\n","        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n","        (static_padding): ZeroPad2d((1, 1, 1, 1))\n","      )\n","      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_se_reduce): Conv2dStaticSamePadding(\n","        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_se_expand): Conv2dStaticSamePadding(\n","        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","        (static_padding): Identity()\n","      )\n","      (_project_conv): Conv2dStaticSamePadding(\n","        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n","        (static_padding): Identity()\n","      )\n","      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","      (_swish): MemoryEfficientSwish()\n","    )\n","  )\n","  (_conv_head): Conv2dStaticSamePadding(\n","    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n","    (static_padding): Identity()\n","  )\n","  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","  (_dropout): Dropout(p=0.2, inplace=False)\n","  (_fc): Linear(in_features=1280, out_features=7, bias=True)\n","  (_swish): MemoryEfficientSwish()\n",")"]},"metadata":{},"execution_count":14}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e3xK-vWXdSW"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 10\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQMcu7oWY2oB","outputId":"a648018d-5b17-4d2b-c0c0-25486fd81e55"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]\n","-------------------------------------------------------------------------------\n","     1      1.6480       1.4083       0.4205      0.5279     ***       1.0\n","     2      1.1927       1.0315       0.5823      0.6486     ***       0.9\n","     3      0.9955       0.9102       0.6409      0.6866     ***       0.9\n","     4      0.8806       0.8146       0.6757      0.7120     ***       0.9\n","     5      0.8101       0.7579       0.7020      0.7276     ***       0.9\n","     6      0.7463       0.7713       0.7287      0.7212               0.9\n","     7      0.6984       0.7172       0.7431      0.7464     ***       0.9\n","     8      0.6691       0.6744       0.7596      0.7678     ***       0.9\n","     9      0.6303       0.6629       0.7706      0.7684     ***       0.9\n","    10      0.6090       0.6800       0.7738      0.7710               0.9\n","-------------------------------------------------------------------------------\n","Total time [min] for 10 Epochs: 9.4\n"]}],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"ojDU7bFshGYM"},"source":["## b1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["b4bf1d5029d94b778b6e442c07bdd331","c336b6edfa4942168b167c4781db6ae8","44ba423570814797853fb4c5fe0a0d89","19893ffcd0ee471ba4b826965c365a9e","bec0629480434598ae2728b5d74c94b8","62b2453f8b9a46e6b0487bf8dd5b3594","828b19643020479191f612f39feb00fd","8213a040930345718d03c2d5c153f1d4","935458623b35446c930d2888e843463c","0181d528385d49f081fc7ba90a4deb4f","10ef99fb69d5418fb83fcf8652418353"]},"id":"i8cldJwrkNTH","outputId":"1c5ea218-e4f4-46eb-c069-4ed93eb9eaec"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4bf1d5029d94b778b6e442c07bdd331","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/30.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b1\n","Initializing Datasets and Dataloaders...\n"]}],"source":["model_name = 'effnetb1'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9sGXy2KkNTH"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 50\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSkBHstjkNTI","outputId":"4861b004-a0af-43f5-f0e3-eb8f4809d9c5"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]\n","-------------------------------------------------------------------------------\n","     1      1.6872       1.4541       0.3995      0.5154     ***       1.5\n","     2      1.2131       1.0042       0.5862      0.6595     ***       1.5\n","     3      0.9797       0.8652       0.6511      0.7111     ***       1.5\n","     4      0.8628       0.7776       0.6903      0.7297     ***       1.5\n","     5      0.7795       0.7019       0.7165      0.7525     ***       1.5\n","     6      0.7178       0.7138       0.7388      0.7509               1.5\n","     7      0.6774       0.6535       0.7542      0.7790     ***       1.5\n","     8      0.6310       0.6369       0.7697      0.7737     ***       1.5\n","     9      0.6007       0.6400       0.7790      0.7799               1.5\n","    10      0.5569       0.6173       0.7990      0.7917     ***       1.5\n","    11      0.5315       0.5986       0.8069      0.8076     ***       1.5\n","    12      0.4995       0.5808       0.8211      0.8041     ***       1.5\n","    13      0.4805       0.6279       0.8247      0.7842               1.5\n","    14      0.4583       0.6001       0.8370      0.8039               1.5\n","    15      0.4386       0.5795       0.8420      0.8149     ***       1.5\n","    16      0.4280       0.5921       0.8456      0.8111               1.5\n","    17      0.4073       0.6070       0.8565      0.7984               1.5\n","    18      0.3950       0.6165       0.8589      0.8131               1.5\n","    19      0.3699       0.5919       0.8716      0.8003               1.5\n","    20      0.3559       0.6140       0.8734      0.8038               1.5\n","    21      0.3500       0.6014       0.8760      0.8121               1.5\n","    22      0.3423       0.6288       0.8734      0.7946               1.5\n","    23      0.3223       0.6282       0.8870      0.7949               1.5\n","    24      0.3132       0.6131       0.8885      0.8002               1.5\n","    25      0.3114       0.6457       0.8875      0.7956               1.5\n","    26      0.3013       0.6451       0.8928      0.8031               1.5\n","    27      0.2984       0.6486       0.8946      0.8036               1.5\n","    28      0.2777       0.6330       0.9021      0.8057               1.5\n","    29      0.2736       0.6382       0.9019      0.8116               1.5\n","    30      0.2623       0.6152       0.9090      0.8093               1.5\n","    31      0.2608       0.6304       0.9105      0.8031               1.5\n","    32      0.2405       0.6236       0.9181      0.8175               1.5\n","    33      0.2547       0.6428       0.9098      0.8069               1.5\n","    34      0.2464       0.6138       0.9160      0.8135               1.5\n","    35      0.2255       0.6610       0.9221      0.8093               1.5\n","    36      0.2226       0.6617       0.9209      0.8084               1.5\n","    37      0.2178       0.6636       0.9260      0.8164               1.5\n","    38      0.2137       0.6775       0.9266      0.8074               1.5\n","    39      0.2045       0.6810       0.9275      0.8105               1.5\n","    40      0.2098       0.6779       0.9288      0.8175               1.5\n","    41      0.2030       0.6981       0.9295      0.8045               1.5\n","    42      0.1865       0.6660       0.9364      0.8100               1.5\n","    43      0.1990       0.6279       0.9291      0.8154               1.5\n","    44      0.1966       0.6417       0.9306      0.8152               1.5\n","    45      0.1994       0.6744       0.9278      0.8032               1.5\n","    46      0.1854       0.6588       0.9392      0.8192               1.5\n","    47      0.1854       0.6538       0.9363      0.8156               1.5\n","    48      0.1770       0.6458       0.9366      0.8192               1.5\n","    49      0.1794       0.6355       0.9355      0.8173               1.5\n","    50      0.1903       0.6286       0.9341      0.8232               1.5\n","-------------------------------------------------------------------------------\n","Total time [min] for 50 Epochs: 75.1\n"]}],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"VO2SdXS5kodc"},"source":["## b2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["6d2052ffd2ca41e7b07d4eff19402c15","a89bfdf644f84e41b2132ba798cfedf9","2d798c4b597148f49090a195e799876e","9625ec38e1d8462ea48cd26b2189bb09","fd4314d7105d4b7aa474eb967908c660","9517164d140944ef896085987eaad1ca","97852afc76e04c6795d197f017ccc495","196fabdd0df8420c8c1775cc8f2e3060","cc0335554aeb477db89a1f3777763aff","c690589f9acb48458087816ec92cd492","966622acab1649d8bfbe820f7d601605"]},"id":"X83r8J9-kqCK","outputId":"665ce038-3a0c-49f7-c7b2-fffaaef783c0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b2-8bb594d6.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d2052ffd2ca41e7b07d4eff19402c15","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/35.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b2\n","Initializing Datasets and Dataloaders...\n"]}],"source":["model_name = 'effnetb2'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EYj8Q8jKkqCK"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 50\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"immT4rKtkqCK","outputId":"6d71df5e-9707-4ff3-c747-cb044f5edcdd"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]\n","-------------------------------------------------------------------------------\n","     1      1.7150       1.5511       0.3877      0.4938     ***       2.0\n","     2      1.2605       1.0795       0.5694      0.6412     ***       2.0\n","     3      1.0269       0.8568       0.6350      0.6972     ***       2.0\n","     4      0.8977       0.7670       0.6720      0.7163     ***       2.0\n","     5      0.7963       0.7008       0.7112      0.7485     ***       2.0\n","     6      0.7341       0.7009       0.7284      0.7477               2.0\n","     7      0.6788       0.6446       0.7541      0.7524     ***       2.0\n","     8      0.6297       0.6199       0.7665      0.7750     ***       2.0\n","     9      0.6093       0.6111       0.7738      0.7811     ***       2.0\n","    10      0.5616       0.6072       0.7958      0.7821     ***       2.0\n","    11      0.5350       0.5892       0.8063      0.7897     ***       2.0\n","    12      0.4966       0.6096       0.8203      0.7894               2.0\n","    13      0.4792       0.5653       0.8241      0.8046     ***       2.0\n","    14      0.4607       0.5738       0.8342      0.8076               2.0\n","    15      0.4351       0.5805       0.8441      0.7958               2.0\n","    16      0.4077       0.5931       0.8549      0.7994               2.0\n","    17      0.4158       0.5731       0.8536      0.8034               2.0\n","    18      0.3848       0.5827       0.8636      0.8001               2.0\n","    19      0.3807       0.5827       0.8592      0.8076               2.0\n","    20      0.3372       0.5956       0.8786      0.8031               2.0\n","    21      0.3418       0.6150       0.8813      0.8065               2.0\n","    22      0.3383       0.5987       0.8798      0.8059               2.0\n","    23      0.3149       0.6022       0.8868      0.8121               2.0\n","    24      0.3083       0.6130       0.8929      0.8008               2.0\n","    25      0.3012       0.6020       0.8936      0.8057               2.0\n","    26      0.2886       0.6307       0.8975      0.8105               2.0\n","    27      0.2656       0.6298       0.9077      0.8078               2.0\n","    28      0.2596       0.6069       0.9088      0.8272               2.0\n","    29      0.2621       0.6459       0.9099      0.8092               2.0\n","    30      0.2336       0.6474       0.9201      0.8223               2.0\n","    31      0.2464       0.6882       0.9131      0.8024               2.0\n","    32      0.2297       0.8294       0.9209      0.7727               2.0\n","    33      0.2338       0.6494       0.9206      0.8227               2.0\n","    34      0.2302       0.6864       0.9169      0.8056               2.0\n","    35      0.2176       0.6731       0.9234      0.8152               2.0\n","    36      0.1994       0.6589       0.9271      0.8142               2.0\n","    37      0.2180       0.6892       0.9261      0.8136               2.0\n","    38      0.2305       0.6590       0.9190      0.8145               2.0\n","    39      0.2095       0.6746       0.9283      0.8207               2.0\n","    40      0.2028       0.6465       0.9331      0.8183               2.0\n","    41      0.2000       0.6466       0.9294      0.8270               2.0\n","    42      0.1935       0.7195       0.9336      0.8057               2.0\n","    43      0.1714       0.7254       0.9376      0.8017               2.0\n","    44      0.1882       0.6944       0.9382      0.8176               2.0\n","    45      0.1682       0.7128       0.9432      0.8065               2.0\n","    46      0.1780       0.7130       0.9380      0.8062               2.0\n","    47      0.1827       0.7566       0.9351      0.8149               2.0\n","    48      0.1766       0.7488       0.9397      0.8055               2.0\n","    49      0.1759       0.6980       0.9385      0.8346               2.0\n","    50      0.1720       0.6661       0.9377      0.8231               2.0\n","-------------------------------------------------------------------------------\n","Total time [min] for 50 Epochs: 98.4\n"]}],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"a0kFDZNJkq9b"},"source":["## b3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["8f07ad3f8d8b4009b28a1583049cbf3d","0a49ba0164684ae0a6843600f1a360f2","86fb359741d64aa7a48dc78471546457","b8912d792b4c47f08ae98a06e8203c6a","b69e7fa96baa4a0f905e59fd0c5b3f44","31fe01729e7141298d656cfc07e09508","c63ba6f74c764d7f9e6303091344dc12","ee7e6263deb64976841103a5adea4699","acc9e58b1518497c92d1ba9a0a196afd","93937f5c5aa949d0970b3aa52fb69e52","2c1b2f0028a64e19bcfd8b555cc2e564"]},"id":"5OUJG-iCksjQ","outputId":"5af786dc-f207-4240-cd83-cf9e44f5f3a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b3-5fb5a3c3.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f07ad3f8d8b4009b28a1583049cbf3d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/47.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b3\n","Initializing Datasets and Dataloaders...\n"]}],"source":["model_name = 'effnetb3'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1YRl8LZksjR"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 50\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ac3HVKa3ksjR","outputId":"389fed0e-e9f8-4285-cc6c-2ccdcfc762ba"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]\n","-------------------------------------------------------------------------------\n","     1      1.6771       1.4356       0.4039      0.5028     ***       3.3\n","     2      1.2073       1.0184       0.5692      0.6297     ***       3.3\n","     3      1.0112       0.8704       0.6322      0.6767     ***       3.3\n","     4      0.8800       0.7757       0.6777      0.7172     ***       3.3\n","     5      0.7657       0.7640       0.7243      0.7226     ***       3.3\n","     6      0.7119       0.7111       0.7379      0.7601     ***       3.3\n","     7      0.6502       0.6466       0.7602      0.7769     ***       3.3\n","     8      0.6037       0.6461       0.7843      0.7657     ***       3.3\n","     9      0.5564       0.6192       0.8017      0.7857     ***       3.3\n","    10      0.5192       0.6787       0.8113      0.7690               3.3\n","    11      0.4824       0.5928       0.8265      0.7992     ***       3.3\n","    12      0.4503       0.5910       0.8377      0.8083     ***       3.3\n","    13      0.4320       0.5993       0.8434      0.8006               3.3\n","    14      0.4130       0.6305       0.8508      0.7988               3.3\n","    15      0.3873       0.6279       0.8616      0.7961               3.3\n","    16      0.3789       0.6259       0.8648      0.7993               3.3\n","    17      0.3493       0.5966       0.8737      0.8100               3.3\n","    18      0.3292       0.5899       0.8856      0.8228     ***       3.3\n","    19      0.3159       0.5990       0.8868      0.8058               3.3\n","    20      0.2975       0.5786       0.8938      0.8298     ***       3.3\n","    21      0.2962       0.7007       0.8956      0.7970               3.3\n","    22      0.2752       0.6389       0.9044      0.8213               3.3\n","    23      0.2610       0.6480       0.9056      0.8194               3.3\n","    24      0.2606       0.6444       0.9060      0.8124               3.3\n","    25      0.2481       0.6292       0.9134      0.8251               3.3\n","    26      0.2458       0.6636       0.9165      0.8176               3.3\n","    27      0.2304       0.6090       0.9200      0.8235               3.3\n","    28      0.2276       0.6275       0.9163      0.8107               3.3\n","    29      0.2308       0.6015       0.9171      0.8296               3.3\n","    30      0.2120       0.6631       0.9275      0.8124               3.3\n","    31      0.2091       0.6219       0.9281      0.8355               3.3\n","    32      0.2015       0.6813       0.9301      0.8268               3.3\n","    33      0.1912       0.6435       0.9372      0.8395               3.3\n","    34      0.1938       0.6498       0.9331      0.8325               3.3\n","    35      0.1932       0.7061       0.9336      0.8218               3.3\n","    36      0.1903       0.6690       0.9300      0.8294               3.3\n","    37      0.1851       0.6864       0.9345      0.8258               3.3\n","    38      0.1769       0.7084       0.9368      0.8220               3.3\n","    39      0.1723       0.6707       0.9392      0.8199               3.3\n","    40      0.1829       0.7117       0.9361      0.8256               3.3\n","    41      0.1691       0.7192       0.9431      0.8277               3.3\n","    42      0.1700       0.6757       0.9420      0.8372               3.3\n","    43      0.1668       0.6743       0.9419      0.8294               3.3\n","    44      0.1421       0.6853       0.9521      0.8282               3.3\n","    45      0.1768       0.7063       0.9397      0.8287               3.3\n","    46      0.1435       0.7060       0.9513      0.8189               3.3\n","    47      0.1579       0.7126       0.9440      0.8223               3.3\n","    48      0.1607       0.6699       0.9440      0.8391               3.3\n","    49      0.1415       0.7331       0.9499      0.8270               3.3\n","    50      0.1523       0.7203       0.9453      0.8372               3.3\n","-------------------------------------------------------------------------------\n","Total time [min] for 50 Epochs: 166.4\n"]}],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"K9jXQqY1kuWM"},"source":["## b4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["59fbcd38eb37498ca544f79df1bd9914"]},"id":"urBeSTTmkvT2","outputId":"0fc36779-50a2-4b48-edc3-195a2491d82e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59fbcd38eb37498ca544f79df1bd9914","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/74.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b4\n","Initializing Datasets and Dataloaders...\n"]}],"source":["model_name = 'effnetb4'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Cx4iCW2ZkvT2"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 30\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"htrl91IQkvT3","outputId":"63fb24f5-72a3-436c-84ff-0f10e345c0ca"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]\n","-------------------------------------------------------------------------------\n","     1      1.5851       1.1609       0.4387      0.6356     ***       6.8\n","     2      1.1104       0.8635       0.5949      0.7064     ***       6.8\n","     3      0.9189       0.8299       0.6576      0.7136     ***       6.8\n","     4      0.8105       0.7236       0.7070      0.7384     ***       6.8\n","     5      0.7202       0.7053       0.7337      0.7511     ***       6.8\n","     6      0.6628       0.6357       0.7519      0.7805     ***       6.8\n","     7      0.6217       0.6401       0.7741      0.7720               6.8\n","     8      0.5618       0.5808       0.7934      0.8095     ***       6.8\n","     9      0.5182       0.6517       0.8096      0.7657               6.8\n","    10      0.4786       0.5776       0.8308      0.8061     ***       6.8\n","    11      0.4440       0.5940       0.8391      0.7994               6.8\n","    12      0.4274       0.6105       0.8467      0.7947               6.8\n","    13      0.3854       0.5638       0.8650      0.8172     ***       6.8\n","    14      0.3777       0.5864       0.8636      0.8133               6.8\n","    15      0.3539       0.6021       0.8760      0.8063               6.8\n","    16      0.3345       0.6790       0.8839      0.7958               6.8\n","    17      0.3227       0.6138       0.8896      0.8066               6.8\n","    18      0.3010       0.6640       0.8961      0.7790               6.8\n","    19      0.2880       0.6455       0.8977      0.7955               6.8\n","    20      0.2661       0.7064       0.9081      0.7947               6.8\n","    21      0.2644       0.6608       0.9070      0.8045               6.8\n","    22      0.2602       0.7149       0.9095      0.7839               6.8\n","    23      0.2371       0.6978       0.9160      0.7934               6.8\n","    24      0.2420       0.6426       0.9144      0.8170               6.8\n","    25      0.2166       0.6648       0.9253      0.8265               6.8\n","    26      0.2230       0.7069       0.9229      0.8114               6.8\n","    27      0.2199       0.7010       0.9219      0.8133               6.8\n","    28      0.2210       0.6722       0.9238      0.8051               6.8\n","    29      0.1970       0.7203       0.9332      0.8042               6.8\n","    30      0.1984       0.7346       0.9326      0.8015               6.8\n","-------------------------------------------------------------------------------\n","Total time [min] for 30 Epochs: 205.2\n"]}],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"AflEBlFWkwPB"},"source":["## b5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O7X98048NcJV"},"outputs":[],"source":["\n","gc.collect()\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["77ff3a94f2d84a40b8a2cc0ee7898315"]},"id":"P2KEb2MHkxlf","outputId":"1278eee9-7998-44e4-e85e-a49e1c3efa35"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b5-b6417697.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77ff3a94f2d84a40b8a2cc0ee7898315","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/117M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b5\n","Initializing Datasets and Dataloaders...\n"]}],"source":["model_name = 'effnetb5'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eI_pRj4akxlf"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 30\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wwnjF6Qxkxlf","outputId":"b6050822-25a6-4e37-b767-5c654011ff9d"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best    Time [min]\n","-------------------------------------------------------------------------------\n","     1      1.5055       1.0902       0.4569      0.6390     ***      14.1\n","     2      1.0261       0.7834       0.6205      0.7267     ***      14.1\n","     3      0.8620       0.6988       0.6801      0.7419     ***      14.1\n","     4      0.7624       0.6511       0.7182      0.7790     ***      14.1\n","     5      0.6813       0.6083       0.7541      0.7924     ***      14.1\n","     6      0.6096       0.5880       0.7800      0.7800     ***      14.1\n","     7      0.5548       0.5773       0.7971      0.8000     ***      14.1\n","     8      0.5080       0.5512       0.8216      0.8143     ***      14.1\n","     9      0.4663       0.6177       0.8310      0.7895              14.1\n","    10      0.4272       0.5530       0.8505      0.8133              14.1\n","    11      0.4102       0.5596       0.8539      0.8171              14.1\n","    12      0.3971       0.6217       0.8588      0.7952              14.1\n","    13      0.3612       0.5605       0.8770      0.8286              14.1\n","    14      0.3262       0.5901       0.8808      0.8133              14.1\n","    15      0.3000       0.5878       0.8965      0.8162              14.1\n","    16      0.2983       0.6374       0.8965      0.8019              14.1\n","    17      0.2790       0.6927       0.9037      0.7943              14.1\n","    18      0.2780       0.6926       0.9004      0.7857              14.1\n","    19      0.2628       0.6231       0.9080      0.8162              14.1\n","    20      0.2500       0.6704       0.9143      0.8076              14.1\n","    21      0.2227       0.7004       0.9257      0.7857              14.1\n","    22      0.2279       0.6991       0.9215      0.7848              14.1\n","    23      0.2139       0.6725       0.9276      0.7857              14.1\n","    24      0.2039       0.6994       0.9317      0.7943              14.1\n","    25      0.1997       0.6445       0.9299      0.8048              14.1\n","    26      0.2002       0.6637       0.9307      0.8048              14.1\n","    27      0.1899       0.7058       0.9356      0.8019              14.1\n","    28      0.1851       0.6743       0.9361      0.8048              14.1\n","    29      0.1920       0.6543       0.9369      0.8010              14.1\n","    30      0.1787       0.6831       0.9385      0.8000              14.1\n","-------------------------------------------------------------------------------\n","Total time [min] for 30 Epochs: 423.7\n"]}],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"pX0WgRwtIh79"},"source":["## b6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["af90c32299f746039e27db4d4bfc4d00"]},"id":"vigbRBHtImSQ","outputId":"a0e4b6ff-582d-4a4b-fac2-e82ad98f7f96"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b6-c76e70fd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b6-c76e70fd.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af90c32299f746039e27db4d4bfc4d00","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/165M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained weights for efficientnet-b6\n","Initializing Datasets and Dataloaders...\n"]}],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb6'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","try:\n","    os.mkdir(saved_models_folder)\n","    os.mkdir(saved_scores_folder)\n","except OSError:\n","    print('Folders already exist!')\n","    pass\n","\n","model, input_size = initialize_model(model_name, 7)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-VBMY4SgImSQ"},"outputs":[],"source":["model = model.to(device)\n","num_epochs = 30\n","save_path = '0'\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aa-LjP7eImSQ"},"outputs":[],"source":["train(model, dataloaders_dict['train'], dataloaders_dict['val'], optimizer, criterion, device, num_epochs,\n","      saved_models_folder, saved_scores_folder, save_path, printfreq=1)"]},{"cell_type":"markdown","metadata":{"id":"VhLb7ewOhJSh"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JY2VauUQjmMM"},"outputs":[],"source":["data_dir = '../exp4val'\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{"id":"lZpvMWIghLL7"},"source":["## b0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJN3_OrVlAsF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"880a7520-120e-4757-8f78-aed51d84c073"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b0\n","Initializing Datasets and Dataloaders...\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb0'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zt5FyNO6hcfC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9c1f146-5f33-4e70-8c99-f0ae28990f14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  = 0.7619047619047619\n","Precision = 0.7652535636406606\n","Recall    = 0.7619047619047619\n","F1        = 0.7635754910928079\n","[[14  8  3  1  4  0  0]\n"," [ 1 25  0  2  2  0  0]\n"," [ 2  1 18  1  6  2  0]\n"," [ 1  0  1 26  1  1  0]\n"," [ 0  1  4  1 19  5  0]\n"," [ 0  1  0  0  1 28  0]\n"," [ 0  0  0  0  0  0 30]]\n"]}],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 32, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]},{"cell_type":"markdown","metadata":{"id":"FHtzZzy-hORv"},"source":["## b1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQQ3LD9atUJE"},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb1'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xu_RVjFtUJE"},"outputs":[],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 32, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]},{"cell_type":"markdown","metadata":{"id":"XpznOS0XhPNr"},"source":["## b2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ws_P7jTmtU5k"},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb2'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2kAAzYhtU5k"},"outputs":[],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 32, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]},{"cell_type":"markdown","metadata":{"id":"876HDZVNhP2_"},"source":["## b3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0L0jjhatVwX"},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb3'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=32)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUtygqeMtVwX"},"outputs":[],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 32, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]},{"cell_type":"markdown","metadata":{"id":"o9cF4dfghQ2Y"},"source":["## b4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4wteFCJtWaq"},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb4'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=16)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lj_GxyeVtWaq"},"outputs":[],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 16, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]},{"cell_type":"markdown","metadata":{"id":"boVsjpTEhRt7"},"source":["## b5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZRIh7x-tXzB"},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb5'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=10)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElD8wsu_tXzB"},"outputs":[],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 10, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]},{"cell_type":"markdown","metadata":{"id":"qiTNoX9MhSdf"},"source":["## b6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aB7RfygtYUJ"},"outputs":[],"source":["gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_name = 'effnetb6'\n","save_path = 'best_0'\n","\n","saved_models_folder = 'saved_models_' + model_name\n","saved_scores_folder = 'saved_scores_' + model_name\n","\n","model, input_size = initialize_model(model_name, 7)\n","model = model.to(device)\n","\n","dataloaders_dict = get_dataloaders(data_dir, input_size, batch_size=5)\n","\n","model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Roo3GShJtYUK"},"outputs":[],"source":["predictions, labels = testing(model, dataloaders_dict['test'], 5, device)\n","Accuracy, Pr, Re, F1, cm = metrics(predictions, labels)\n","\n","print('Accuracy  = ' + str(Accuracy))\n","print('Precision = ' + str(Pr))\n","print('Recall    = ' + str(Re))\n","print('F1        = ' + str(F1))\n","print(cm)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0181d528385d49f081fc7ba90a4deb4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a49ba0164684ae0a6843600f1a360f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31fe01729e7141298d656cfc07e09508","placeholder":"​","style":"IPY_MODEL_c63ba6f74c764d7f9e6303091344dc12","value":"100%"}},"10ef99fb69d5418fb83fcf8652418353":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"196fabdd0df8420c8c1775cc8f2e3060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19893ffcd0ee471ba4b826965c365a9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0181d528385d49f081fc7ba90a4deb4f","placeholder":"​","style":"IPY_MODEL_10ef99fb69d5418fb83fcf8652418353","value":" 30.1M/30.1M [00:01&lt;00:00, 26.7MB/s]"}},"2c1b2f0028a64e19bcfd8b555cc2e564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d798c4b597148f49090a195e799876e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_196fabdd0df8420c8c1775cc8f2e3060","max":36804509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc0335554aeb477db89a1f3777763aff","value":36804509}},"31fe01729e7141298d656cfc07e09508":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44ba423570814797853fb4c5fe0a0d89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8213a040930345718d03c2d5c153f1d4","max":31519111,"min":0,"orientation":"horizontal","style":"IPY_MODEL_935458623b35446c930d2888e843463c","value":31519111}},"62b2453f8b9a46e6b0487bf8dd5b3594":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d2052ffd2ca41e7b07d4eff19402c15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a89bfdf644f84e41b2132ba798cfedf9","IPY_MODEL_2d798c4b597148f49090a195e799876e","IPY_MODEL_9625ec38e1d8462ea48cd26b2189bb09"],"layout":"IPY_MODEL_fd4314d7105d4b7aa474eb967908c660"}},"8213a040930345718d03c2d5c153f1d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"828b19643020479191f612f39feb00fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86fb359741d64aa7a48dc78471546457":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee7e6263deb64976841103a5adea4699","max":49388949,"min":0,"orientation":"horizontal","style":"IPY_MODEL_acc9e58b1518497c92d1ba9a0a196afd","value":49388949}},"8f07ad3f8d8b4009b28a1583049cbf3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a49ba0164684ae0a6843600f1a360f2","IPY_MODEL_86fb359741d64aa7a48dc78471546457","IPY_MODEL_b8912d792b4c47f08ae98a06e8203c6a"],"layout":"IPY_MODEL_b69e7fa96baa4a0f905e59fd0c5b3f44"}},"935458623b35446c930d2888e843463c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93937f5c5aa949d0970b3aa52fb69e52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9517164d140944ef896085987eaad1ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9625ec38e1d8462ea48cd26b2189bb09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c690589f9acb48458087816ec92cd492","placeholder":"​","style":"IPY_MODEL_966622acab1649d8bfbe820f7d601605","value":" 35.1M/35.1M [00:01&lt;00:00, 20.2MB/s]"}},"966622acab1649d8bfbe820f7d601605":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97852afc76e04c6795d197f017ccc495":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a89bfdf644f84e41b2132ba798cfedf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9517164d140944ef896085987eaad1ca","placeholder":"​","style":"IPY_MODEL_97852afc76e04c6795d197f017ccc495","value":"100%"}},"acc9e58b1518497c92d1ba9a0a196afd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4bf1d5029d94b778b6e442c07bdd331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c336b6edfa4942168b167c4781db6ae8","IPY_MODEL_44ba423570814797853fb4c5fe0a0d89","IPY_MODEL_19893ffcd0ee471ba4b826965c365a9e"],"layout":"IPY_MODEL_bec0629480434598ae2728b5d74c94b8"}},"b69e7fa96baa4a0f905e59fd0c5b3f44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8912d792b4c47f08ae98a06e8203c6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93937f5c5aa949d0970b3aa52fb69e52","placeholder":"​","style":"IPY_MODEL_2c1b2f0028a64e19bcfd8b555cc2e564","value":" 47.1M/47.1M [00:01&lt;00:00, 35.5MB/s]"}},"bec0629480434598ae2728b5d74c94b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c336b6edfa4942168b167c4781db6ae8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b2453f8b9a46e6b0487bf8dd5b3594","placeholder":"​","style":"IPY_MODEL_828b19643020479191f612f39feb00fd","value":"100%"}},"c63ba6f74c764d7f9e6303091344dc12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c690589f9acb48458087816ec92cd492":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc0335554aeb477db89a1f3777763aff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee7e6263deb64976841103a5adea4699":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd4314d7105d4b7aa474eb967908c660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}